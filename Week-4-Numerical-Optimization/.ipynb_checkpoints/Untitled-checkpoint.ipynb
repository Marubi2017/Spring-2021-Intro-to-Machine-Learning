{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact and Gradient-Based OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinaryLeastSquaresExact:\n",
    "        \n",
    "    # fit the model to the data\n",
    "    def fit(self, X, y):\n",
    "        # save the training data\n",
    "        self.data = np.hstack((np.ones([X.shape[0],1]), X))\n",
    "        \n",
    "        # save the training labels\n",
    "        self.outputs = y\n",
    "        \n",
    "        # find the theta values that minimize the sum of squared errors\n",
    "        X = self.data\n",
    "        self.theta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "                \n",
    "    # predict the output from input (testing) data\n",
    "    def predict(self, X):\n",
    "        # initialize an empty matrix to store the predicted outputs\n",
    "        yPredicted = np.empty([X.shape[0],1])\n",
    "        \n",
    "        # append a column of ones at the beginning of X\n",
    "        X = np.hstack((np.ones([X.shape[0],1]), X))\n",
    "        \n",
    "        # apply the function f with the values of theta from the fit function to each testing datapoint\n",
    "        for row in range(X.shape[0]):\n",
    "            yPredicted[row] = self.theta @ X[row,]\n",
    "            \n",
    "        return yPredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[6], [7], [8], [9], [7]])\n",
    "y = np.array([1, 2, 3, 3, 4])\n",
    "\n",
    "print('FOR THE GRADIENT-BASED ORDINARY LEAST SQUARES CODE')\n",
    "\n",
    "# instantiate an OLS (gradient) object, fit to data, predict data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print the predictions\n",
    "print('\\nThe predicted y values are', predictions.T[0])\n",
    "\n",
    "# print the real y values\n",
    "print('The real y values are', y)\n",
    "\n",
    "# print the theta values\n",
    "parameters = model.theta\n",
    "print('The theta values are', parameters)\n",
    "\n",
    "# plot the training points\n",
    "plt.scatter(X, y, label = 'Training Data')\n",
    "\n",
    "# plot the fitted model with the training data\n",
    "xModel = np.linspace(6,10,100)\n",
    "yModel = parameters[0] + parameters[1]*xModel\n",
    "lineFormula = 'y={:.3f}+{:.3f}x'.format(parameters[0], parameters[1])\n",
    "plt.plot(xModel, yModel, 'r', label = lineFormula)\n",
    "\n",
    "# add a legend\n",
    "plt.legend()\n",
    "\n",
    "# return quality metrics\n",
    "print('The r^2 score is', r2_score(y, predictions))\n",
    "print('The mean absolute error is', mean_absolute_error(y, predictions),'\\n')\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "print('FOR THE EXACT ORDINARY LEAST SQUARES CODE \\n')\n",
    "\n",
    "# instantiate an OLS (exact) object, fit to data, predict data\n",
    "model = OrdinaryLeastSquaresExact()\n",
    "model.fit(X,y)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# print the predictions\n",
    "print('The predicted y values are', predictions.T[0])\n",
    "\n",
    "# print the real y values\n",
    "print('The real y values are', y)\n",
    "\n",
    "# print the theta values\n",
    "parameters = model.theta\n",
    "print('The theta values are', parameters)\n",
    "\n",
    "# plot the fitted model with the training data\n",
    "xModel = np.linspace(6,10,100)\n",
    "yModel = parameters[0] + parameters[1]*xModel\n",
    "lineFormula = 'y={:.3f}+{:.3f}x'.format(parameters[0], parameters[1])\n",
    "plt.plot(xModel, yModel, 'g', label = lineFormula)\n",
    "\n",
    "# add a legend\n",
    "plt.legend()\n",
    "\n",
    "# return quality metrics\n",
    "print('The r^2 score is', r2_score(y, predictions))\n",
    "print('The mean absolute error is', mean_absolute_error(y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Graduation Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data from the csv file to an numpy array\n",
    "data = pd.read_csv('data/US_State_Data.csv', sep=',').to_numpy()\n",
    "#print(data)\n",
    "X = np.array(data[:,1:7], dtype=float)\n",
    "y = np.array(data[:,8], dtype=float)\n",
    "\n",
    "# split the data into training and test sets\n",
    "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('FOR THE GRADIENT-BASED ORDINARY LEAST SQUARES CODE')\n",
    "\n",
    "# instantiate an OLS model and fit the model to the training data (find the theta parameters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return the predicted outputs for the datapoints in the training set\n",
    "trainPredictions = model.predict(trainX)\n",
    "\n",
    "# print the coefficient of determination r^2\n",
    "print('\\nThe r^2 score is', r2_score(trainY, trainPredictions))\n",
    "\n",
    "# print quality metrics\n",
    "print('The mean absolute error on the training set is', mean_absolute_error(trainY, trainPredictions))\n",
    "\n",
    "# return the predicted outputs for the datapoints in the test set\n",
    "predictions = model.predict(testX)\n",
    "\n",
    "# print the predictions\n",
    "print('The predicted y values for the test set are', np.round(predictions.T[0],0))\n",
    "\n",
    "# print the real y values\n",
    "print('The real y values for the test set are     ', testY)\n",
    "\n",
    "# print the theta values\n",
    "print('The theta values are', model.theta)\n",
    "\n",
    "# print quality metrics\n",
    "print('The mean absolute error on the test set is', mean_absolute_error(testY, predictions), '\\n')\n",
    "\n",
    "##################################################################\n",
    "\n",
    "print('FOR THE EXACT ORDINARY LEAST SQUARES CODE \\n')\n",
    "\n",
    "# instantiate an OLS model\n",
    "model = OrdinaryLeastSquaresExact()\n",
    "\n",
    "# fit the model to the training data (find the theta parameters)\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "# return the predicted outputs for the datapoints in the training set\n",
    "trainPredictions = model.predict(trainX)\n",
    "\n",
    "# print the coefficient of determination r^2\n",
    "print('The r^2 score is', r2_score(trainY, trainPredictions))\n",
    "\n",
    "# print quality metrics\n",
    "print('The mean absolute error on the training set is', mean_absolute_error(trainY, trainPredictions))\n",
    "\n",
    "# return the predicted outputs for the datapoints in the test set\n",
    "predictions = model.predict(testX)\n",
    "\n",
    "# print the predictions\n",
    "print('The predicted y values for the test set are', np.round(predictions.T[0],0))\n",
    "\n",
    "# print the real y values\n",
    "print('The real y values for the test set are     ', testY)\n",
    "\n",
    "# print the theta values\n",
    "print('The theta values are', model.theta)\n",
    "\n",
    "# print quality metrics\n",
    "print('The mean absolute error on the test set is', mean_absolute_error(testY, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Based Kernel Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianKernel(x0, x, lam):\n",
    "    return (1/lam) * np.exp(-np.linalg.norm(x0 - x) / (2 * lam))\n",
    "\n",
    "class KernelRegression:\n",
    "    def __init__(self, kernel_function, lam, fit_intercept = True):\n",
    "        self.kernel_function = kernel_function\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.lam = lam\n",
    "\n",
    "    def predict(self, x0, X, y):\n",
    "        # find the number of X points\n",
    "        n = X.shape[0]\n",
    "        \n",
    "        # add a column of ones if needed\n",
    "        if self.fit_intercept:\n",
    "            X = np.hstack((np.ones([n,1]), X))\n",
    "\n",
    "        # construct the kernel matrix\n",
    "        kernel = np.zeros([n, n])\n",
    "        \n",
    "        # populate the kernel matrix\n",
    "        for i in range(n):\n",
    "            kernel[i][i] = self.kernel_function(x0, X[i,:], self.lam)\n",
    "                \n",
    "        return np.array([1, np.float(x0)]) @ np.linalg.inv((X.T @ kernel @ X)) @ X.T @ kernel @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the shampoo sales dataset\n",
    "data = pd.read_csv('data/shampoo.csv')\n",
    "\n",
    "# save the targets\n",
    "y = data['Sales'].to_numpy()\n",
    "\n",
    "# make a column vector of 0s with n elements\n",
    "X = np.zeros([y.shape[0], 1])\n",
    "\n",
    "# convert the vector to (0, 1, 2, ..., n)\n",
    "X[:,0] = [i for i in range(y.shape[0])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split the data into train and test sets\n",
    "(trainX, testX, trainY, testY) = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamValues = np.linspace(0.025, 10, 200)\n",
    "\n",
    "M = lamValues.shape[0]\n",
    "\n",
    "# allow multiple plots\n",
    "fig, axes = plt.subplots(nrows = M + 1, figsize = (10, 4*M))\n",
    "\n",
    "trainMAE = []\n",
    "testMAE = []\n",
    "\n",
    "for (j, lam) in enumerate(lamValues):\n",
    "    model = KernelRegression(GaussianKernel, lam)\n",
    "\n",
    "    # compute the model coordinates\n",
    "    xModel = [i for i in range(int(np.round(1.1 * np.max(X))))]\n",
    "    yModel = [model.predict(i, trainX, trainY) for i in xModel]\n",
    "\n",
    "    # plot the model\n",
    "    label = 'Kernel Smoothing for lambda = ' + str(np.round(lam, 2))\n",
    "    axes[j].scatter(X, y)\n",
    "    axes[j].plot(xModel, yModel, 'r', label = label)\n",
    "    axes[j].legend()\n",
    "    \n",
    "    # apply the functions to the test data and predict with the model\n",
    "    trainPredictions = [model.predict(i, trainX, trainY) for i in trainX]\n",
    "    testPredictions = [model.predict(i, trainX, trainY) for i in testX]\n",
    "    \n",
    "    # compute the training and test mean absolute error\n",
    "    trainError = mean_absolute_error(trainY, trainPredictions)\n",
    "    testError = mean_absolute_error(testY, testPredictions)\n",
    "    \n",
    "    # save the training and test mean absolute error\n",
    "    trainMAE.append(trainError)\n",
    "    testMAE.append(testError)\n",
    "\n",
    "    # return quality metrics\n",
    "    print('lambda:', np.round(lam, 3), '\\t\\tr^2:', np.round(r2_score(trainY, trainPredictions), 3),\n",
    "          '\\t\\ttrain MAE:', np.round(trainError, 3), '\\t\\ttest MAE:', np.round(testError, 3))\n",
    "    \n",
    "# plot the errors\n",
    "axes[M].plot(range(M), trainMAE, label = 'Training Mean Absolute Error')\n",
    "axes[M].plot(range(M), testMAE, label = 'Testing Mean Absolute Error')\n",
    "axes[M].legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
